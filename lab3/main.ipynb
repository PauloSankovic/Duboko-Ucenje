{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3. vježba: analiza klasifikacije sentimenta"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Zadatak 1. Učitavanje podataka (25% bodova)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words: 14804\n",
      "the\t-> 5954\n",
      "a\t-> 4361\n",
      "and\t-> 3831\n",
      "of\t-> 3631\n",
      "to\t-> 2438\n"
     ]
    }
   ],
   "source": [
    "from util import get_word_frequency_sorted\n",
    "\n",
    "frequencies = get_word_frequency_sorted(\"./data/sst_train_raw.csv\")\n",
    "\n",
    "print(\"Total number of words:\", len(frequencies))\n",
    "for word, freq in list(frequencies.items())[:5]:\n",
    "    print(f\"{word}\\t-> {freq}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "special_symbols = {'<PAD>': 0, '<UNK>': 1}\n",
    "label_frequency = {\"positive\": 2, \"negative\": 1}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PAD> -> 0\n",
      "<UNK> -> 1\n",
      "the -> 2\n",
      "a -> 3\n",
      "and -> 4\n",
      "my -> 188\n",
      "twists -> 930\n",
      "lets -> 956\n",
      "sports -> 1275\n",
      "amateurishly -> 6818\n"
     ]
    }
   ],
   "source": [
    "from vocab import Vocab\n",
    "\n",
    "data_vocab = Vocab(frequencies, max_size=-1, min_freq=0, special_symbols=special_symbols)\n",
    "stoi = data_vocab.stoi\n",
    "\n",
    "for word in ['<PAD>', '<UNK>', 'the', 'a', 'and', 'my', 'twists', 'lets', 'sports', 'amateurishly']:\n",
    "    print(f\"{word} -> {stoi[word]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive -> 0\n",
      "negative -> 1\n"
     ]
    }
   ],
   "source": [
    "label_vocab = Vocab({}, max_size=-1, min_freq=0, special_symbols=label_frequency)\n",
    "stoi = label_vocab.stoi\n",
    "\n",
    "for word, index in stoi.items():\n",
    "    print(f\"{word} -> {index}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: ['yet', 'the', 'act', 'is', 'still', 'charming', 'here']\n",
      "Label: positive\n",
      "Numericalized text: tensor([189,   2, 674,   7, 129, 348, 143], dtype=torch.int32)\n",
      "Numericalized label: 0\n"
     ]
    }
   ],
   "source": [
    "from dataset import NlpDataset\n",
    "\n",
    "train_dataset = NlpDataset('./data/sst_train_raw.csv', data_vocab, label_vocab)\n",
    "instance_text, instance_label = train_dataset.instances[3]\n",
    "print(\"Text:\", instance_text)\n",
    "print(\"Label:\", instance_label)\n",
    "\n",
    "numericalized_text, numericalized_label = train_dataset[3]\n",
    "print(f\"Numericalized text: {numericalized_text}\")\n",
    "print(f\"Numericalized label: {numericalized_label}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts: tensor([[   2,  554,    7, 2872,    6,   22,    2, 2873, 1236,    8,   96, 4800,\n",
      "            4,   10,   72,    8,  242,    6,   75,    3, 3576,   56, 3577,   34,\n",
      "         2022, 2874, 7123, 3578, 7124,   42,  779, 7125,    0,    0],\n",
      "        [   2, 2875, 2023, 4801,    5,    2, 3579,    5,    2, 2876, 4802,    7,\n",
      "           40,  829,   10,    3, 4803,    5,  627,   62,   27, 2877, 2024, 4804,\n",
      "          962,  715,    8, 7126,  555,    5, 7127, 4805,    8, 7128]],\n",
      "       dtype=torch.int32)\n",
      "Labels: tensor([0, 0], dtype=torch.int32)\n",
      "Lengths: tensor([32, 34])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from util import pad_collate_fn\n",
    "\n",
    "batch_size = 2\n",
    "shuffle = False\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=pad_collate_fn)\n",
    "texts, labels, lengths = next(iter(train_dataloader))\n",
    "\n",
    "print(f\"Texts: {texts}\")\n",
    "print(f\"Labels: {labels}\")\n",
    "print(f\"Lengths: {lengths}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "%reset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Zadatak 2. Implementacija baseline modela (25% bodova)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "SAVE_DIR = './models/basic'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "\n",
    "SEED = 7052020\n",
    "VOCAB_MAX_SIZE = -1\n",
    "VOCAB_MIN_FREQ = 1\n",
    "TRAIN_BATCH_SIZE = 10\n",
    "VALID_BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "LR = 1e-4\n",
    "SHUFFLE = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from loader import vocab_data_loader\n",
    "\n",
    "train_dataloader, valid_dataloader, test_dataloader, embeddings = vocab_data_loader(\n",
    "    seed=SEED,\n",
    "    vocab_max_size=VOCAB_MAX_SIZE,\n",
    "    vocab_min_freq=VOCAB_MIN_FREQ,\n",
    "    train_bs=TRAIN_BATCH_SIZE,\n",
    "    valid_bs=VALID_BATCH_SIZE,\n",
    "    test_bs=TEST_BATCH_SIZE,\n",
    "    shuffle=SHUFFLE\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 1:\n",
      "\tAccuracy: 0.6005780346820809, Loss: 0.6669273212810473\n",
      "Validate epoch 1:\n",
      "\tAccuracy: 0.7084019769357496, Loss: 0.6123208236276058\n",
      "Train epoch 2:\n",
      "\tAccuracy: 0.7320809248554914, Loss: 0.5555407534961756\n",
      "Validate epoch 2:\n",
      "\tAccuracy: 0.7484898407468424, Loss: 0.5330309935829096\n",
      "Train epoch 3:\n",
      "\tAccuracy: 0.7673410404624278, Loss: 0.5031714297701858\n",
      "Validate epoch 3:\n",
      "\tAccuracy: 0.7902251510159253, Loss: 0.48953733580154285\n",
      "Train epoch 4:\n",
      "\tAccuracy: 0.7802023121387284, Loss: 0.4815769983250971\n",
      "Validate epoch 4:\n",
      "\tAccuracy: 0.7660626029654036, Loss: 0.49232064997940733\n",
      "Train epoch 5:\n",
      "\tAccuracy: 0.7833815028901734, Loss: 0.4717148376811791\n",
      "Validate epoch 5:\n",
      "\tAccuracy: 0.7913234486545854, Loss: 0.4711927844766985\n",
      "Train epoch 6:\n",
      "\tAccuracy: 0.7933526011560693, Loss: 0.4612705295937771\n",
      "Validate epoch 6:\n",
      "\tAccuracy: 0.7764964305326744, Loss: 0.479785015185674\n",
      "Train epoch 7:\n",
      "\tAccuracy: 0.7946531791907514, Loss: 0.4570081312467769\n",
      "Validate epoch 7:\n",
      "\tAccuracy: 0.7891268533772653, Loss: 0.46540531516075134\n",
      "Train epoch 8:\n",
      "\tAccuracy: 0.7965317919075144, Loss: 0.44933597545403275\n",
      "Validate epoch 8:\n",
      "\tAccuracy: 0.7951674903898956, Loss: 0.46119402113713714\n",
      "Train epoch 9:\n",
      "\tAccuracy: 0.7946531791907514, Loss: 0.44425997191857053\n",
      "Validate epoch 9:\n",
      "\tAccuracy: 0.7880285557386052, Loss: 0.4641955777218467\n",
      "Train epoch 10:\n",
      "\tAccuracy: 0.796242774566474, Loss: 0.4425529719820257\n",
      "Validate epoch 10:\n",
      "\tAccuracy: 0.7737506864360242, Loss: 0.47129787217106733\n",
      "Train epoch 11:\n",
      "\tAccuracy: 0.8005780346820809, Loss: 0.435831504179477\n",
      "Validate epoch 11:\n",
      "\tAccuracy: 0.8017572762218561, Loss: 0.4543969986731546\n",
      "Train epoch 12:\n",
      "\tAccuracy: 0.8028901734104046, Loss: 0.43224995406721367\n",
      "Validate epoch 12:\n",
      "\tAccuracy: 0.7984623833058759, Loss: 0.45241878482333403\n",
      "Train epoch 13:\n",
      "\tAccuracy: 0.8036127167630058, Loss: 0.4282793104325588\n",
      "Validate epoch 13:\n",
      "\tAccuracy: 0.7918725974739155, Loss: 0.4541207201648177\n",
      "Train epoch 14:\n",
      "\tAccuracy: 0.8069364161849711, Loss: 0.4241888213504343\n",
      "Validate epoch 14:\n",
      "\tAccuracy: 0.786381109280615, Loss: 0.4571808550441474\n",
      "Train epoch 15:\n",
      "\tAccuracy: 0.8054913294797688, Loss: 0.4217129679493649\n",
      "Validate epoch 15:\n",
      "\tAccuracy: 0.7935200439319056, Loss: 0.4516273940864362\n",
      "Train epoch 16:\n",
      "\tAccuracy: 0.8060693641618497, Loss: 0.4203535740322977\n",
      "Validate epoch 16:\n",
      "\tAccuracy: 0.7869302580999451, Loss: 0.4533946163821639\n",
      "Train epoch 17:\n",
      "\tAccuracy: 0.8085260115606936, Loss: 0.41445606966325316\n",
      "Validate epoch 17:\n",
      "\tAccuracy: 0.7759472817133443, Loss: 0.464806099471293\n",
      "Train epoch 18:\n",
      "\tAccuracy: 0.8132947976878613, Loss: 0.41311712406920215\n",
      "Validate epoch 18:\n",
      "\tAccuracy: 0.7929708951125755, Loss: 0.447592333220599\n",
      "Train epoch 19:\n",
      "\tAccuracy: 0.8119942196531792, Loss: 0.4096869663093131\n",
      "Validate epoch 19:\n",
      "\tAccuracy: 0.7990115321252059, Loss: 0.4452415848510307\n",
      "Train epoch 20:\n",
      "\tAccuracy: 0.8158959537572255, Loss: 0.40599988026253747\n",
      "Validate epoch 20:\n",
      "\tAccuracy: 0.7819879187259747, Loss: 0.450452258712367\n",
      "Train epoch 21:\n",
      "\tAccuracy: 0.8177745664739884, Loss: 0.40366897812769936\n",
      "Validate epoch 21:\n",
      "\tAccuracy: 0.785282811641955, Loss: 0.4471446500535597\n",
      "Train epoch 22:\n",
      "\tAccuracy: 0.8173410404624277, Loss: 0.4003981417314166\n",
      "Validate epoch 22:\n",
      "\tAccuracy: 0.7836353651839648, Loss: 0.447493875235842\n",
      "Train epoch 23:\n",
      "\tAccuracy: 0.8222543352601156, Loss: 0.3993901040383502\n",
      "Validate epoch 23:\n",
      "\tAccuracy: 0.7825370675453048, Loss: 0.4651862035195033\n",
      "Train epoch 24:\n",
      "\tAccuracy: 0.8236994219653179, Loss: 0.39439130367743486\n",
      "Validate epoch 24:\n",
      "\tAccuracy: 0.7962657880285557, Loss: 0.44712373143748235\n",
      "Train epoch 25:\n",
      "\tAccuracy: 0.8235549132947977, Loss: 0.39039463787797213\n",
      "Validate epoch 25:\n",
      "\tAccuracy: 0.7523338824821527, Loss: 0.4852707082765144\n",
      "Train epoch 26:\n",
      "\tAccuracy: 0.8265895953757225, Loss: 0.3878331982256102\n",
      "Validate epoch 26:\n",
      "\tAccuracy: 0.7924217462932455, Loss: 0.4421700103241101\n",
      "Train epoch 27:\n",
      "\tAccuracy: 0.8255780346820809, Loss: 0.38398098222093086\n",
      "Validate epoch 27:\n",
      "\tAccuracy: 0.7781438769906645, Loss: 0.45287408849649263\n",
      "Train epoch 28:\n",
      "\tAccuracy: 0.830635838150289, Loss: 0.3794962346898338\n",
      "Validate epoch 28:\n",
      "\tAccuracy: 0.786381109280615, Loss: 0.4434467491350676\n",
      "Train epoch 29:\n",
      "\tAccuracy: 0.8338150289017341, Loss: 0.3758274267099238\n",
      "Validate epoch 29:\n",
      "\tAccuracy: 0.7913234486545854, Loss: 0.4451209897534889\n",
      "Train epoch 30:\n",
      "\tAccuracy: 0.8348265895953757, Loss: 0.37230854716173484\n",
      "Validate epoch 30:\n",
      "\tAccuracy: 0.7869302580999451, Loss: 0.4422526997432374\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "from baseline import Baseline\n",
    "from engine import train, evaluate\n",
    "from util import get_metrics\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "model = Baseline(embeddings)\n",
    "\n",
    "criterion = BCEWithLogitsLoss()\n",
    "optimizer = Adam(model.parameters(), lr=LR)\n",
    "\n",
    "baseline_writer = SummaryWriter('runs/baseline')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    loss, y_pred, y_true = train(model, train_dataloader, optimizer, criterion, -1)\n",
    "    torch.save(model, SAVE_DIR + f\"/baseline/epoch-{epoch}.pickle\")\n",
    "    accuracy, precision, recall, f1 = get_metrics(y_pred, y_true)\n",
    "\n",
    "    baseline_writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "    baseline_writer.add_scalar(\"Accuracy/train\", accuracy, epoch)\n",
    "    baseline_writer.add_scalar(\"Precision/train\", precision, epoch)\n",
    "    baseline_writer.add_scalar(\"Recall/train\", recall, epoch)\n",
    "    baseline_writer.add_scalar(\"F1/train\", f1, epoch)\n",
    "\n",
    "    print(f\"Train epoch {epoch}:\")\n",
    "    print(f\"\\tAccuracy: {accuracy}, Loss: {loss}\")\n",
    "\n",
    "    loss, y_pred, y_true = evaluate(model, valid_dataloader, criterion)\n",
    "    accuracy, precision, recall, f1 = get_metrics(y_pred, y_true)\n",
    "\n",
    "    baseline_writer.add_scalar(\"Loss/validate\", loss, epoch)\n",
    "    baseline_writer.add_scalar(\"Accuracy/validate\", accuracy, epoch)\n",
    "    baseline_writer.add_scalar(\"Precision/validate\", precision, epoch)\n",
    "    baseline_writer.add_scalar(\"Recall/validate\", recall, epoch)\n",
    "    baseline_writer.add_scalar(\"F1/validate\", f1, epoch)\n",
    "\n",
    "    print(f\"Validate epoch {epoch}:\")\n",
    "    print(f\"\\tAccuracy: {accuracy}, Loss: {loss}\")\n",
    "\n",
    "baseline_writer.flush()\n",
    "baseline_writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results:\n",
      "\tAccuracy: 0.7786697247706422, Loss: 0.44540453223245485\n"
     ]
    }
   ],
   "source": [
    "BEST_EPOCH = 19\n",
    "\n",
    "model = torch.load(SAVE_DIR + f\"/baseline/epoch-{BEST_EPOCH}.pickle\")\n",
    "\n",
    "loss, y_pred, y_true = evaluate(model, test_dataloader, criterion)\n",
    "accuracy, precision, recall, f1 = get_metrics(y_pred, y_true)\n",
    "\n",
    "print(\"Test results:\")\n",
    "print(f\"\\tAccuracy: {accuracy}, Loss: {loss}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "%reset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Zadatak 3. Implementacija povratne neuronske mreže (25% bodova)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "SAVE_DIR = './models/basic'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "\n",
    "SEED = 7052020\n",
    "VOCAB_MAX_SIZE = -1\n",
    "VOCAB_MIN_FREQ = 1\n",
    "TRAIN_BATCH_SIZE = 10\n",
    "VALID_BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "LR = 1e-4\n",
    "GRADIENT_CLIP = 0.25\n",
    "SHUFFLE = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "from loader import vocab_data_loader\n",
    "\n",
    "train_dataloader, valid_dataloader, test_dataloader, embeddings = vocab_data_loader(\n",
    "    seed=SEED,\n",
    "    vocab_max_size=VOCAB_MAX_SIZE,\n",
    "    vocab_min_freq=VOCAB_MIN_FREQ,\n",
    "    train_bs=TRAIN_BATCH_SIZE,\n",
    "    valid_bs=VALID_BATCH_SIZE,\n",
    "    test_bs=TEST_BATCH_SIZE,\n",
    "    shuffle=SHUFFLE\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rnn(\n",
      "  (embeddings): Embedding(7123, 300, padding_idx=0)\n",
      "  (rnn): GRU(300, 300)\n",
      "  (fc1): Linear(in_features=300, out_features=150, bias=True)\n",
      "  (fc2): Linear(in_features=150, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from rnn import Rnn\n",
    "\n",
    "MODE = 'gru'\n",
    "model = Rnn(embeddings, mode=MODE)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 0:\n",
      "\tAccuracy: 0.522543352601156, Loss: 0.6921697370923323\n",
      "Validate epoch 0:\n",
      "\tAccuracy: 0.5063152114222954, Loss: 0.692521149652046\n",
      "Train epoch 1:\n",
      "\tAccuracy: 0.7213872832369942, Loss: 0.5529462322377401\n",
      "Validate epoch 1:\n",
      "\tAccuracy: 0.7759472817133443, Loss: 0.49551953296912343\n",
      "Train epoch 2:\n",
      "\tAccuracy: 0.7903179190751445, Loss: 0.47280673084059205\n",
      "Validate epoch 2:\n",
      "\tAccuracy: 0.7726523887973641, Loss: 0.5305561208934114\n",
      "Train epoch 3:\n",
      "\tAccuracy: 0.8005780346820809, Loss: 0.4480341517587187\n",
      "Validate epoch 3:\n",
      "\tAccuracy: 0.8034047226798462, Loss: 0.4495425242603871\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-7-9d88a4a010f1>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mEPOCHS\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 20\u001B[1;33m     \u001B[0mloss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_true\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_dataloader\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mGRADIENT_CLIP\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     21\u001B[0m     \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msave\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mSAVE_DIR\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;34mf\"/rnn/epoch-{epoch}.pickle\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m     \u001B[0maccuracy\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprecision\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrecall\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mf1\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_metrics\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_pred\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_true\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Programming\\Duboko Ucenje\\lab3\\engine.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(model, dataloader, optimizer, criterion, grad_clip)\u001B[0m\n\u001B[0;32m     16\u001B[0m         \u001B[0mlogits\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlogits\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m         \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlogits\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfloat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 18\u001B[1;33m         \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     19\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mgrad_clip\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m             \u001B[0mclip_grad_norm_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrad_clip\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\paulo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    243\u001B[0m                 \u001B[0mcreate_graph\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    244\u001B[0m                 inputs=inputs)\n\u001B[1;32m--> 245\u001B[1;33m         \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    246\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    247\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\paulo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\autograd\\__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    143\u001B[0m         \u001B[0mretain_graph\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    144\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 145\u001B[1;33m     Variable._execution_engine.run_backward(\n\u001B[0m\u001B[0;32m    146\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    147\u001B[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "from engine import train, evaluate\n",
    "from util import get_metrics\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "criterion = BCEWithLogitsLoss()\n",
    "optimizer = Adam(model.parameters(), lr=LR)\n",
    "\n",
    "rnn_writer = SummaryWriter(f'runs/{MODE}')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    loss, y_pred, y_true = train(model, train_dataloader, optimizer, criterion, GRADIENT_CLIP)\n",
    "    torch.save(model, SAVE_DIR + f\"/{MODE}/epoch-{epoch}.pickle\")\n",
    "    accuracy, precision, recall, f1 = get_metrics(y_pred, y_true)\n",
    "\n",
    "    rnn_writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "    rnn_writer.add_scalar(\"Accuracy/train\", accuracy, epoch)\n",
    "    rnn_writer.add_scalar(\"Precision/train\", precision, epoch)\n",
    "    rnn_writer.add_scalar(\"Recall/train\", recall, epoch)\n",
    "    rnn_writer.add_scalar(\"F1/train\", f1, epoch)\n",
    "\n",
    "    print(f\"Train epoch {epoch}:\")\n",
    "    print(f\"\\tAccuracy: {accuracy}, Loss: {loss}\")\n",
    "\n",
    "    loss, y_pred, y_true = evaluate(model, valid_dataloader, criterion)\n",
    "    accuracy, precision, recall, f1 = get_metrics(y_pred, y_true)\n",
    "\n",
    "    rnn_writer.add_scalar(\"Loss/validate\", loss, epoch)\n",
    "    rnn_writer.add_scalar(\"Accuracy/validate\", accuracy, epoch)\n",
    "    rnn_writer.add_scalar(\"Precision/validate\", precision, epoch)\n",
    "    rnn_writer.add_scalar(\"Recall/validate\", recall, epoch)\n",
    "    rnn_writer.add_scalar(\"F1/validate\", f1, epoch)\n",
    "\n",
    "    print(f\"Validate epoch {epoch}:\")\n",
    "    print(f\"\\tAccuracy: {accuracy}, Loss: {loss}\")\n",
    "\n",
    "rnn_writer.flush()\n",
    "rnn_writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results:\n",
      "\tAccuracy: 0.7901376146788991, Loss: 0.4403384306601116\n"
     ]
    }
   ],
   "source": [
    "BEST_EPOCH = 6\n",
    "\n",
    "model = torch.load(SAVE_DIR + f\"/lstm/epoch-{BEST_EPOCH}.pickle\")\n",
    "\n",
    "loss, y_pred, y_true = evaluate(model, test_dataloader, criterion)\n",
    "accuracy, precision, recall, f1 = get_metrics(y_pred, y_true)\n",
    "\n",
    "print(\"Test results:\")\n",
    "print(f\"\\tAccuracy: {accuracy}, Loss: {loss}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing done.\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Zadatak 4. Usporedba modela i pretraga hiperparametara (25% bodova)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bidirectional"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "SAVE_DIR = './models/vs=300_bs=10_ls=2_drop=0.45_bidir'\n",
    "LOG_SAVE_DIR = './runs/vs=300_bs=10_ls=2_drop=0.45_bidir'\n",
    "os.mkdir(SAVE_DIR)\n",
    "os.mkdir(LOG_SAVE_DIR)\n",
    "\n",
    "for mode in ['rnn', 'lstm', 'gru']:\n",
    "    os.mkdir(SAVE_DIR + '/' + mode)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "\n",
    "SEED = 7052020\n",
    "VOCAB_MAX_SIZE = -1\n",
    "VOCAB_MIN_FREQ = 1\n",
    "TRAIN_BATCH_SIZE = 10\n",
    "VALID_BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "LR = 1e-4\n",
    "GRADIENT_CLIP = 0.25\n",
    "DROPOUT = 0.45\n",
    "LAYERS = 2\n",
    "SHUFFLE = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from loader import vocab_data_loader\n",
    "from rnn import Rnn\n",
    "\n",
    "import torch\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "from engine import train, evaluate\n",
    "from util import get_metrics\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "for MODE in ['rnn', 'lstm', 'gru']:\n",
    "    train_dataloader, valid_dataloader, test_dataloader, embeddings = vocab_data_loader(\n",
    "        seed=SEED,\n",
    "        vocab_max_size=VOCAB_MAX_SIZE,\n",
    "        vocab_min_freq=VOCAB_MIN_FREQ,\n",
    "        train_bs=TRAIN_BATCH_SIZE,\n",
    "        valid_bs=VALID_BATCH_SIZE,\n",
    "        test_bs=TEST_BATCH_SIZE,\n",
    "        shuffle=SHUFFLE\n",
    "    )\n",
    "\n",
    "    model = Rnn(embeddings, mode=MODE, bidirectional=True, layers=LAYERS, dropout=DROPOUT)\n",
    "    print(model)\n",
    "\n",
    "    criterion = BCEWithLogitsLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=LR)\n",
    "\n",
    "    writer = SummaryWriter(f'{LOG_SAVE_DIR}/{MODE}')\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        loss, y_pred, y_true = train(model, train_dataloader, optimizer, criterion, GRADIENT_CLIP)\n",
    "        torch.save(model, SAVE_DIR + f\"/{MODE}/epoch-{epoch}.pickle\")\n",
    "        accuracy, precision, recall, f1 = get_metrics(y_pred, y_true)\n",
    "\n",
    "        writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "        writer.add_scalar(\"Accuracy/train\", accuracy, epoch)\n",
    "        writer.add_scalar(\"Precision/train\", precision, epoch)\n",
    "        writer.add_scalar(\"Recall/train\", recall, epoch)\n",
    "        writer.add_scalar(\"F1/train\", f1, epoch)\n",
    "\n",
    "        print(f\"Train epoch {epoch}:\")\n",
    "        print(f\"\\tAccuracy: {accuracy}, Loss: {loss}\")\n",
    "\n",
    "        loss, y_pred, y_true = evaluate(model, valid_dataloader, criterion)\n",
    "        accuracy, precision, recall, f1 = get_metrics(y_pred, y_true)\n",
    "\n",
    "        writer.add_scalar(\"Loss/validate\", loss, epoch)\n",
    "        writer.add_scalar(\"Accuracy/validate\", accuracy, epoch)\n",
    "        writer.add_scalar(\"Precision/validate\", precision, epoch)\n",
    "        writer.add_scalar(\"Recall/validate\", recall, epoch)\n",
    "        writer.add_scalar(\"F1/validate\", f1, epoch)\n",
    "\n",
    "        print(f\"Validate epoch {epoch}:\")\n",
    "        print(f\"\\tAccuracy: {accuracy}, Loss: {loss}\")\n",
    "\n",
    "    writer.flush()\n",
    "    writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hyperparameters Optimization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "\n",
    "fixed_params = {\n",
    "    'seed': 7052020,\n",
    "    'epochs': 10,\n",
    "    'min_frequency': 1,\n",
    "    'lr': 1e-4,\n",
    "    'grad_clip': 0.25\n",
    "}\n",
    "\n",
    "VALID_BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 32\n",
    "SHUFFLE = True\n",
    "\n",
    "variable_params = {\n",
    "    'vs': [200, 14804],     # vocabulary size\n",
    "    'bs': [1, 160],         # batch size\n",
    "    'ls': [1, 4],           # layer size\n",
    "    'drop': [0, 0.69],      # dropout\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from loader import vocab_data_loader\n",
    "from rnn import Rnn\n",
    "\n",
    "import torch\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "from engine import train, evaluate\n",
    "from util import get_metrics\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import os\n",
    "from itertools import product\n",
    "\n",
    "MODE = 'gru'\n",
    "for vs, bs, ls, drop in product(variable_params['vs'], variable_params['bs'], variable_params['ls'], variable_params['drop']):\n",
    "    print(vs, bs, ls, drop)\n",
    "    train_dataloader, valid_dataloader, test_dataloader, embeddings = vocab_data_loader(\n",
    "        seed=fixed_params['seed'],\n",
    "        vocab_max_size=vs,\n",
    "        vocab_min_freq=fixed_params['min_frequency'],\n",
    "        train_bs=bs,\n",
    "        valid_bs=VALID_BATCH_SIZE,\n",
    "        test_bs=TEST_BATCH_SIZE,\n",
    "        shuffle=SHUFFLE\n",
    "    )\n",
    "\n",
    "    model = Rnn(embeddings, mode=MODE, bidirectional=True, layers=ls, dropout=drop, hidden_size=150)\n",
    "    print(model)\n",
    "\n",
    "    criterion = BCEWithLogitsLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=fixed_params['lr'])\n",
    "\n",
    "    filename = f\"gru_vs={vs}_bs={bs}_ls={ls}_drop={drop}_bidir\".replace(\".\", \"\")\n",
    "\n",
    "    SAVE_DIR = f'./models/{filename}'\n",
    "    os.mkdir(SAVE_DIR)\n",
    "\n",
    "    writer = SummaryWriter(f'/runs')\n",
    "\n",
    "    for epoch in range(fixed_params['epochs']):\n",
    "        loss, y_pred, y_true = train(model, train_dataloader, optimizer, criterion, fixed_params['grad_clip'])\n",
    "        torch.save(model, SAVE_DIR + f\"/epoch-{epoch}.pickle\")\n",
    "        accuracy, precision, recall, f1 = get_metrics(y_pred, y_true)\n",
    "\n",
    "        writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "        writer.add_scalar(\"Accuracy/train\", accuracy, epoch)\n",
    "        writer.add_scalar(\"Precision/train\", precision, epoch)\n",
    "        writer.add_scalar(\"Recall/train\", recall, epoch)\n",
    "        writer.add_scalar(\"F1/train\", f1, epoch)\n",
    "\n",
    "        print(f\"Train epoch {epoch}:\")\n",
    "        print(f\"\\tAccuracy: {accuracy}, Loss: {loss}\")\n",
    "\n",
    "        loss, y_pred, y_true = evaluate(model, valid_dataloader, criterion)\n",
    "        accuracy, precision, recall, f1 = get_metrics(y_pred, y_true)\n",
    "\n",
    "        writer.add_scalar(\"Loss/validate\", loss, epoch)\n",
    "        writer.add_scalar(\"Accuracy/validate\", accuracy, epoch)\n",
    "        writer.add_scalar(\"Precision/validate\", precision, epoch)\n",
    "        writer.add_scalar(\"Recall/validate\", recall, epoch)\n",
    "        writer.add_scalar(\"F1/validate\", f1, epoch)\n",
    "\n",
    "        print(f\"Validate epoch {epoch}:\")\n",
    "        print(f\"\\tAccuracy: {accuracy}, Loss: {loss}\")\n",
    "\n",
    "    writer.flush()\n",
    "    writer.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}